{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-96612b83c6e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# HTR Dependency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# HTR Dependency\n",
    "import cv2\n",
    "import string\n",
    "import h5py\n",
    "\n",
    "keras = tf.keras\n",
    "print(tf.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1.0-dev20191224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: nvidia-smi: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "import re\n",
    "import string\n",
    "\n",
    "\"\"\"\n",
    "DeepSpell based text cleaning process.\n",
    "    Tal Weiss.\n",
    "    Deep Spelling.\n",
    "    Medium: https://machinelearnings.co/deep-spelling-9ffef96a24f6#.2c9pu8nlm\n",
    "    Github: https://github.com/MajorTal/DeepSpell\n",
    "\"\"\"\n",
    "\n",
    "RE_DASH_FILTER = re.compile(r'[\\-\\˗\\֊\\‐\\‑\\‒\\–\\—\\⁻\\₋\\−\\﹣\\－]', re.UNICODE)\n",
    "RE_APOSTROPHE_FILTER = re.compile(r'&#39;|[ʼ՚＇‘’‛❛❜ߴߵ`‵´ˊˋ{}{}{}{}{}{}{}{}{}]'.format(\n",
    "    chr(768), chr(769), chr(832), chr(833), chr(2387),\n",
    "    chr(5151), chr(5152), chr(65344), chr(8242)), re.UNICODE)\n",
    "RE_RESERVED_CHAR_FILTER = re.compile(r'[¶¤«»]', re.UNICODE)\n",
    "RE_LEFT_PARENTH_FILTER = re.compile(r'[\\(\\[\\{\\⁽\\₍\\❨\\❪\\﹙\\（]', re.UNICODE)\n",
    "RE_RIGHT_PARENTH_FILTER = re.compile(r'[\\)\\]\\}\\⁾\\₎\\❩\\❫\\﹚\\）]', re.UNICODE)\n",
    "RE_BASIC_CLEANER = re.compile(r'[^\\w\\s{}]'.format(re.escape(string.punctuation)), re.UNICODE)\n",
    "\n",
    "LEFT_PUNCTUATION_FILTER = \"\"\"!%&),.:;<=>?@\\\\]^_`|}~\"\"\"\n",
    "RIGHT_PUNCTUATION_FILTER = \"\"\"\"(/<=>@[\\\\^_`{|~\"\"\"\n",
    "NORMALIZE_WHITESPACE_REGEX = re.compile(r'[^\\S\\n]+', re.UNICODE)\n",
    "\n",
    "def text_standardize(text):\n",
    "    \"\"\"Organize/add spaces around punctuation marks\"\"\"\n",
    "\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "\n",
    "    text = html.unescape(text).replace(\"\\\\n\", \"\").replace(\"\\\\t\", \"\")\n",
    "\n",
    "    text = RE_RESERVED_CHAR_FILTER.sub(\"\", text)\n",
    "    text = RE_DASH_FILTER.sub(\"-\", text)\n",
    "    text = RE_APOSTROPHE_FILTER.sub(\"'\", text)\n",
    "    text = RE_LEFT_PARENTH_FILTER.sub(\"(\", text)\n",
    "    text = RE_RIGHT_PARENTH_FILTER.sub(\")\", text)\n",
    "    text = RE_BASIC_CLEANER.sub(\"\", text)\n",
    "\n",
    "    text = text.lstrip(LEFT_PUNCTUATION_FILTER)\n",
    "    text = text.rstrip(RIGHT_PUNCTUATION_FILTER)\n",
    "    text = text.translate(str.maketrans({c: f\" {c} \" for c in string.punctuation}))\n",
    "    text = NORMALIZE_WHITESPACE_REGEX.sub(\" \", text.strip())\n",
    "\n",
    "    return text\n",
    "\n",
    "\"\"\"\n",
    "Sauvola binarization based in,\n",
    "    J. Sauvola, T. Seppanen, S. Haapakoski, M. Pietikainen,\n",
    "    Adaptive Document Binarization, in IEEE Computer Society Washington, 1997.\n",
    "\"\"\"\n",
    "\n",
    "def sauvola(img, window, thresh, k):\n",
    "    \"\"\"Sauvola binarization\"\"\"\n",
    "\n",
    "    rows, cols = img.shape\n",
    "    pad = int(np.floor(window[0] / 2))\n",
    "    sum2, sqsum = cv2.integral2(\n",
    "        cv2.copyMakeBorder(img, pad, pad, pad, pad, cv2.BORDER_CONSTANT))\n",
    "\n",
    "    isum = sum2[window[0]:rows + window[0], window[1]:cols + window[1]] + \\\n",
    "        sum2[0:rows, 0:cols] - \\\n",
    "        sum2[window[0]:rows + window[0], 0:cols] - \\\n",
    "        sum2[0:rows, window[1]:cols + window[1]]\n",
    "\n",
    "    isqsum = sqsum[window[0]:rows + window[0], window[1]:cols + window[1]] + \\\n",
    "        sqsum[0:rows, 0:cols] - \\\n",
    "        sqsum[window[0]:rows + window[0], 0:cols] - \\\n",
    "        sqsum[0:rows, window[1]:cols + window[1]]\n",
    "\n",
    "    ksize = window[0] * window[1]\n",
    "    mean = isum / ksize\n",
    "    std = (((isqsum / ksize) - (mean**2) / ksize) / ksize) ** 0.5\n",
    "    threshold = (mean * (1 + k * (std / thresh - 1))) * (mean >= 100)\n",
    "\n",
    "    return np.asarray(255 * (img >= threshold), 'uint8')\n",
    "\n",
    "def remove_cursive_style(img):\n",
    "    \"\"\"Remove cursive writing style from image with deslanting algorithm\"\"\"\n",
    "\n",
    "    def calc_y_alpha(vec):\n",
    "        indices = np.where(vec > 0)[0]\n",
    "        h_alpha = len(indices)\n",
    "\n",
    "        if h_alpha > 0:\n",
    "            delta_y_alpha = indices[h_alpha - 1] - indices[0] + 1\n",
    "\n",
    "            if h_alpha == delta_y_alpha:\n",
    "                return h_alpha * h_alpha\n",
    "        return 0\n",
    "\n",
    "    alpha_vals = [-1.0, -0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "    rows, cols = img.shape\n",
    "    results = []\n",
    "\n",
    "    ret, otsu = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    binary = otsu if ret < 127 else sauvola(img, (int(img.shape[0] / 2), int(img.shape[0] / 2)), 127, 1e-2)\n",
    "\n",
    "    for alpha in alpha_vals:\n",
    "        shift_x = max(-alpha * rows, 0.)\n",
    "        size = (cols + int(np.ceil(abs(alpha * rows))), rows)\n",
    "        transform = np.asarray([[1, alpha, shift_x], [0, 1, 0]], dtype=np.float)\n",
    "\n",
    "        shear_img = cv2.warpAffine(binary, transform, size, cv2.INTER_NEAREST)\n",
    "        sum_alpha = 0\n",
    "        sum_alpha += np.apply_along_axis(calc_y_alpha, 0, shear_img)\n",
    "        results.append([np.sum(sum_alpha), size, transform])\n",
    "\n",
    "    result = sorted(results, key=lambda x: x[0], reverse=True)[0]\n",
    "    warp = cv2.warpAffine(img, result[2], result[1], borderValue=255)\n",
    "\n",
    "    return cv2.resize(warp, dsize=(cols, rows))\n",
    "\n",
    "def preproc(img, input_size):\n",
    "    \"\"\"Make the process with the `input_size` to the scale resize\"\"\"\n",
    "    img_src = img\n",
    "    if isinstance(img, str):\n",
    "        img = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if isinstance(img, tuple):\n",
    "        image, boundbox = img\n",
    "        img = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        for i in range(len(boundbox)):\n",
    "            if isinstance(boundbox[i], float):\n",
    "                total = len(img) if i < 2 else len(img[0])\n",
    "                boundbox[i] = int(total * boundbox[i])\n",
    "\n",
    "        img = np.asarray(img[boundbox[0]:boundbox[1], boundbox[2]:boundbox[3]], dtype=np.uint8)\n",
    "\n",
    "    wt, ht, _ = input_size\n",
    "    try:\n",
    "        h, w = np.asarray(img).shape\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {img_src}\")\n",
    "        return\n",
    "\n",
    "    f = max((w / wt), (h / ht))\n",
    "\n",
    "    new_size = (max(min(wt, int(w / f)), 1), max(min(ht, int(h / f)), 1))\n",
    "    img = cv2.resize(img, new_size)\n",
    "\n",
    "    _, binary = cv2.threshold(img, 254, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    if np.sum(img) * 0.8 > np.sum(binary):\n",
    "        img = illumination_compensation(img)\n",
    "\n",
    "    img = remove_cursive_style(img)\n",
    "\n",
    "    target = np.ones([ht, wt], dtype=np.uint8) * 255\n",
    "    target[0:new_size[1], 0:new_size[0]] = img\n",
    "    img = cv2.transpose(target)\n",
    "\n",
    "    return img\n",
    "\n",
    "def normalization(imgs):\n",
    "    \"\"\"Normalize list of images\"\"\"\n",
    "\n",
    "    imgs = np.asarray(imgs).astype(np.float32)\n",
    "    _, h, w = imgs.shape\n",
    "\n",
    "    for i in range(len(imgs)):\n",
    "        m, s = cv2.meanStdDev(imgs[i])\n",
    "        imgs[i] = imgs[i] - m[0][0]\n",
    "        imgs[i] = imgs[i] / s[0][0] if s[0][0] > 0 else imgs[i]\n",
    "\n",
    "    return np.expand_dims(imgs, axis=-1)\n",
    "\n",
    "\n",
    "def augmentation(imgs,\n",
    "                 rotation_range=0,\n",
    "                 scale_range=0,\n",
    "                 height_shift_range=0,\n",
    "                 width_shift_range=0,\n",
    "                 dilate_range=1,\n",
    "                 erode_range=1):\n",
    "    \"\"\"Apply variations to a list of images (rotate, width and height shift, scale, erode, dilate)\"\"\"\n",
    "\n",
    "    imgs = imgs.astype(np.float32)\n",
    "    _, h, w = imgs.shape\n",
    "\n",
    "    dilate_kernel = np.ones((int(np.random.uniform(1, dilate_range)),), np.uint8)\n",
    "    erode_kernel = np.ones((int(np.random.uniform(1, erode_range)),), np.uint8)\n",
    "    height_shift = np.random.uniform(-height_shift_range, height_shift_range)\n",
    "    rotation = np.random.uniform(-rotation_range, rotation_range)\n",
    "    scale = np.random.uniform(1 - scale_range, 1)\n",
    "    width_shift = np.random.uniform(-width_shift_range, width_shift_range)\n",
    "\n",
    "    trans_map = np.float32([[1, 0, width_shift * w], [0, 1, height_shift * h]])\n",
    "    rot_map = cv2.getRotationMatrix2D((w // 2, h // 2), rotation, scale)\n",
    "\n",
    "    trans_map_aff = np.r_[trans_map, [[0, 0, 1]]]\n",
    "    rot_map_aff = np.r_[rot_map, [[0, 0, 1]]]\n",
    "    affine_mat = rot_map_aff.dot(trans_map_aff)[:2, :]\n",
    "\n",
    "    for i in range(len(imgs)):\n",
    "        imgs[i] = cv2.warpAffine(imgs[i], affine_mat, (w, h), flags=cv2.INTER_NEAREST, borderValue=255)\n",
    "        imgs[i] = cv2.erode(imgs[i], erode_kernel, iterations=1)\n",
    "        imgs[i] = cv2.dilate(imgs[i], dilate_kernel, iterations=1)\n",
    "\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTR-experiment.ipynb     dataset_generator.py     main.py\r\n",
      "HTR.ipynb                iam_word_Flor.tflite     main_exp.py\r\n",
      "\u001b[1m\u001b[36mModels\u001b[m\u001b[m                   iam_word_Flor_htr.tflite parameter.txt\r\n",
      "\u001b[1m\u001b[36mTFlite\u001b[m\u001b[m                   \u001b[1m\u001b[36mlog\u001b[m\u001b[m                      \u001b[1m\u001b[36msaved_model\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36mWord\u001b[m\u001b[m                     \u001b[1m\u001b[36mlogs\u001b[m\u001b[m                     \u001b[1m\u001b[36mtarget\u001b[m\u001b[m\r\n",
      "datasetGenerator.ipynb   main                     tensorboard.ipynb\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3e619abcde14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Uses generator functions to supply train/test with data.\n",
    "Image renderings and text are created on the fly each time.\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "class DataGenerator():\n",
    "    \"\"\"Generator class with data streaming\"\"\"\n",
    "\n",
    "    def __init__(self, source, batch_size, charset, max_text_length, predict=False):\n",
    "        self.tokenizer = Tokenizer(charset, max_text_length)\n",
    "        self.batch_size = batch_size\n",
    "        self.partitions = ['test'] if predict else ['train', 'valid', 'test']\n",
    "\n",
    "        self.size = dict()\n",
    "        self.steps = dict()\n",
    "        self.index = dict()\n",
    "        self.dataset = dict()\n",
    "\n",
    "        with h5py.File(source, \"r\") as f:\n",
    "            for pt in self.partitions:\n",
    "                self.dataset[pt] = dict()\n",
    "                self.dataset[pt]['dt'] = f[pt]['dt'][:]\n",
    "                self.dataset[pt]['gt'] = f[pt]['gt'][:]\n",
    "\n",
    "        for pt in self.partitions:\n",
    "            # decode sentences from byte\n",
    "            self.dataset[pt]['gt'] = [x.decode() for x in self.dataset[pt]['gt']]\n",
    "\n",
    "            # set size and setps\n",
    "            self.size[pt] = len(self.dataset[pt]['gt'])\n",
    "            self.steps[pt] = int(np.ceil(self.size[pt] / self.batch_size))\n",
    "            self.index[pt] = 0\n",
    "\n",
    "    def next_train_batch(self):\n",
    "        \"\"\"Get the next batch from train partition (yield)\"\"\"\n",
    "\n",
    "        while True:\n",
    "            if self.index['train'] >= self.size['train']:\n",
    "                self.index['train'] = 0\n",
    "\n",
    "            index = self.index['train']\n",
    "            until = self.index['train'] + self.batch_size\n",
    "            self.index['train'] = until\n",
    "\n",
    "            x_train = self.dataset['train']['dt'][index:until]\n",
    "            y_train = self.dataset['train']['gt'][index:until]\n",
    "\n",
    "            x_train = augmentation(x_train,\n",
    "                                      rotation_range=1.5,\n",
    "                                      scale_range=0.05,\n",
    "                                      height_shift_range=0.025,\n",
    "                                      width_shift_range=0.05,\n",
    "                                      erode_range=5,\n",
    "                                      dilate_range=3)\n",
    "\n",
    "            x_train = normalization(x_train)\n",
    "\n",
    "            y_train = [self.tokenizer.encode(y) for y in y_train]\n",
    "            y_train = pad_sequences(y_train, maxlen=self.tokenizer.maxlen, padding=\"post\")\n",
    "\n",
    "            yield (x_train, y_train, [])\n",
    "\n",
    "    def next_valid_batch(self):\n",
    "        \"\"\"Get the next batch from validation partition (yield)\"\"\"\n",
    "\n",
    "        while True:\n",
    "            if self.index['valid'] >= self.size['valid']:\n",
    "                self.index['valid'] = 0\n",
    "\n",
    "            index = self.index['valid']\n",
    "            until = self.index['valid'] + self.batch_size\n",
    "            self.index['valid'] = until\n",
    "\n",
    "            x_valid = self.dataset['valid']['dt'][index:until]\n",
    "            y_valid = self.dataset['valid']['gt'][index:until]\n",
    "\n",
    "            x_valid = normalization(x_valid)\n",
    "\n",
    "            y_valid = [self.tokenizer.encode(y) for y in y_valid]\n",
    "            y_valid = pad_sequences(y_valid, maxlen=self.tokenizer.maxlen, padding=\"post\")\n",
    "\n",
    "            yield (x_valid, y_valid, [])\n",
    "\n",
    "    def next_test_batch(self):\n",
    "        \"\"\"Return model predict parameters\"\"\"\n",
    "\n",
    "        while True:\n",
    "            if self.index['test'] >= self.size['test']:\n",
    "                self.index['test'] = 0\n",
    "                break\n",
    "\n",
    "            index = self.index['test']\n",
    "            until = self.index['test'] + self.batch_size\n",
    "            self.index['test'] = until\n",
    "\n",
    "            x_test = self.dataset['test']['dt'][index:until]\n",
    "            x_test = normalization(x_test)\n",
    "\n",
    "            yield x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer():\n",
    "    \"\"\"Manager tokens functions and charset/dictionary properties\"\"\"\n",
    "\n",
    "    def __init__(self, chars, max_text_length=128):\n",
    "        self.PAD_TK, self.UNK_TK = \"¶\", \"¤\"\n",
    "        self.chars = (self.PAD_TK + self.UNK_TK + chars)\n",
    "\n",
    "        self.PAD = self.chars.find(self.PAD_TK)\n",
    "        self.UNK = self.chars.find(self.UNK_TK)\n",
    "\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.maxlen = max_text_length\n",
    "\n",
    "    def encode(self, text):\n",
    "        \"\"\"Encode text to vector\"\"\"\n",
    "\n",
    "        text = unicodedata.normalize(\"NFKD\", text).encode(\"ASCII\", \"ignore\").decode(\"ASCII\")\n",
    "        text = \" \".join(text.split())\n",
    "        encoded = []\n",
    "\n",
    "        for item in text:\n",
    "            index = self.chars.find(item)\n",
    "            index = self.UNK if index == -1 else index\n",
    "            encoded.append(index)\n",
    "\n",
    "        return np.asarray(encoded)\n",
    "\n",
    "    def decode(self, text):\n",
    "        \"\"\"Decode vector to text\"\"\"\n",
    "\n",
    "        decoded = \"\".join([self.chars[int(x)] for x in text if x > -1])\n",
    "        decoded = self.remove_tokens(decoded)\n",
    "        decoded = text_standardize(decoded)\n",
    "\n",
    "        return decoded\n",
    "\n",
    "    def remove_tokens(self, text):\n",
    "        \"\"\"Remove tokens (PAD) from text\"\"\"\n",
    "\n",
    "        return text.replace(self.PAD_TK, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuadmin01/terng\n",
      "chuck_iam_dataset.hdf5\t       Fonts\t\t\t saved_model\r\n",
      "Dataset\t\t\t       HTR_dataset_word\t\t SeniorProjectMaterial\r\n",
      "dataset_10000.hdf5\t       HTR_generated_dataset\t test_daaset.hdf5\r\n",
      "dataset_filter_large.hdf5      iam_word_Flor_htr.tflite  test.png\r\n",
      "dataset_iam_gen_32maxlen.hdf5  Parallel\r\n",
      "dataset_iam_gen.hdf5\t       PytorchServer\r\n"
     ]
    }
   ],
   "source": [
    "%cd '/home/kuadmin01/terng/'\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sprecial_char = ['_', '?', '!', '\"', \"'\", '+', '-', '*', '/']\n",
    "CHARSET_BASE_filter = string.ascii_uppercase+string.ascii_lowercase\n",
    "for c in sprecial_char:\n",
    "    CHARSET_BASE_filter += c\n",
    "    \n",
    "INPUT_SOURCE_NAME = \"iam_word\"\n",
    "BATCH_SIZE = 16\n",
    "MAX_TEXT_LENGTH = 128\n",
    "\n",
    "dtgen = DataGenerator(\n",
    "          source=f\"/home/kuadmin01/terng/dataset_filter_large.hdf5\",\n",
    "          batch_size=BATCH_SIZE,\n",
    "          charset=CHARSET_BASE_filter,\n",
    "          max_text_length=MAX_TEXT_LENGTH,\n",
    "          predict=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SOURCE_NAME = \"iam_word\"\n",
    "BATCH_SIZE = 16\n",
    "MAX_TEXT_LENGTH = 32\n",
    "CHARSET_BASE = string.printable[:95]\n",
    "\n",
    "dtgen = DataGenerator(\n",
    "          source=f\"/home/kuadmin01/terng/dataset_filter.hdf5\",\n",
    "          batch_size=BATCH_SIZE,\n",
    "          charset=CHARSET_BASE,\n",
    "          max_text_length=MAX_TEXT_LENGTH,\n",
    "          predict=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE = \" \"\n",
    "SPECIAL_CHARS = \"?!,.\"\n",
    "ALPHANUMERIC = string.printable[:62]\n",
    "CHARS = ALPHANUMERIC + SPECIAL_CHARS + SPACE\n",
    "CHARS\n",
    "\n",
    "INPUT_SOURCE_NAME = \"iam_word\"\n",
    "BATCH_SIZE = 16\n",
    "MAX_TEXT_LENGTH = 32\n",
    "CHARSET_BASE = CHARS\n",
    "\n",
    "dtgen = DataGenerator(\n",
    "          source=f\"/home/kuadmin01/terng/Dataset/dataset_filter.hdf5\",\n",
    "          batch_size=BATCH_SIZE,\n",
    "          charset=CHARSET_BASE,\n",
    "          max_text_length=MAX_TEXT_LENGTH,\n",
    "          predict=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sprecial_char = ['_', '?', '!', '\"', \"'\", '+', '-', '*', '/']\n",
    "CHARSET_BASE_filter = string.ascii_uppercase+string.ascii_lowercase\n",
    "for c in sprecial_char:\n",
    "    CHARSET_BASE_filter += c\n",
    "len(CHARSET_BASE_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_loss(y_true, y_pred):\n",
    "    \"\"\"Function for computing the CTC loss\"\"\"\n",
    "    \n",
    "    if len(y_true.shape) > 2:\n",
    "        y_true = tf.squeeze(y_true)\n",
    "\n",
    "    input_length = tf.math.reduce_sum(y_pred, axis=-1, keepdims=False)\n",
    "    input_length = tf.math.reduce_sum(input_length, axis=-1, keepdims=True)\n",
    "    label_length = tf.math.count_nonzero(y_true, axis=-1, keepdims=True, dtype=\"int64\")\n",
    "\n",
    "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "from Models.HTR_Models import FlorHTR, SmallFlorHTR, PuigCerver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_SHAPE = dtgen.tokenizer.vocab_size + 1\n",
    "OUTPUT_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 1024, 128, 1)]    0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 512, 64, 16)       160       \n",
      "_________________________________________________________________\n",
      "p_re_lu (PReLU)              (None, 512, 64, 16)       16        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512, 64, 16)       112       \n",
      "_________________________________________________________________\n",
      "full_gated_conv2d (FullGated (None, 512, 64, 16)       4640      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 512, 64, 32)       4640      \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 512, 64, 32)       32        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512, 64, 32)       224       \n",
      "_________________________________________________________________\n",
      "full_gated_conv2d_1 (FullGat (None, 512, 64, 32)       18496     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 16, 40)       10280     \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 256, 16, 40)       40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256, 16, 40)       280       \n",
      "_________________________________________________________________\n",
      "full_gated_conv2d_2 (FullGat (None, 256, 16, 40)       28880     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256, 16, 40)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 256, 16, 48)       17328     \n",
      "_________________________________________________________________\n",
      "p_re_lu_3 (PReLU)            (None, 256, 16, 48)       48        \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256, 16, 48)       336       \n",
      "_________________________________________________________________\n",
      "full_gated_conv2d_3 (FullGat (None, 256, 16, 48)       41568     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256, 16, 48)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 128, 4, 56)        21560     \n",
      "_________________________________________________________________\n",
      "p_re_lu_4 (PReLU)            (None, 128, 4, 56)        56        \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128, 4, 56)        392       \n",
      "_________________________________________________________________\n",
      "full_gated_conv2d_4 (FullGat (None, 128, 4, 56)        56560     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128, 4, 56)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 4, 64)        32320     \n",
      "_________________________________________________________________\n",
      "p_re_lu_5 (PReLU)            (None, 128, 4, 64)        64        \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128, 4, 64)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 2, 64)        0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 128, 128)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128, 256)          198144    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 128, 128)          32896     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128, 256)          198144    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 128, 70)           17990     \n",
      "=================================================================\n",
      "Total params: 685,654\n",
      "Trainable params: 684,374\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = (1024, 128, 1)\n",
    "OUTPUT_SHAPE = dtgen.tokenizer.vocab_size + 1\n",
    "\n",
    "inputs, outputs = FlorHTR(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=5e-4), loss=ctc_loss)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def Callback(source, model_name):\n",
    "      callbacks = [\n",
    "        ModelCheckpoint(\n",
    "          filepath=f\"target/\"+ str(model_name) + \"/\" + str(source)  + \"_checkpoint_weights.hdf5\",\n",
    "          monitor=\"val_loss\",\n",
    "          save_best_only=True,\n",
    "          save_weights_only=True,\n",
    "          verbose=True\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "          monitor=\"val_loss\",\n",
    "          min_delta=1e-8,\n",
    "          patience=20,\n",
    "          restore_best_weights=True,\n",
    "          verbose=True\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "          monitor=\"val_loss\",\n",
    "          min_delta=1e-8,\n",
    "          factor=0.2,\n",
    "          patience=15,\n",
    "          verbose=True\n",
    "        ),\n",
    "        CSVLogger(\n",
    "          filename=f\"log/\"+ str(model_name) + \"/\" + str(source)  + \"_epochs.log\",\n",
    "          separator=\";\",\n",
    "          append=True\n",
    "        ),\n",
    "      ]\n",
    "      return callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iam_word'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SOURCE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = Callback(INPUT_SOURCE_NAME, 'Flor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(f\"/home/kuadmin01/terng/SeniorProjectMaterial/target/Flor/iam_word_checkpoint_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuadmin01/terng/SeniorProjectMaterial\n",
      "Train for 21486 steps, validate for 3054 steps\n",
      "  107/21486 [..............................] - ETA: 2:00:25 - loss: 0.5332WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n",
      "  107/21486 [..............................] - ETA: 2:00:28 - loss: 0.5285"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1277ed45e873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m           )\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             batch_end=step * batch_size + current_batch_size)\n\u001b[1;32m    180\u001b[0m       \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m       \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_batch\u001b[0;34m(self, step, mode, size)\u001b[0m\n\u001b[1;32m    787\u001b[0m           self.callbacks._call_batch_hook(\n\u001b[1;32m    788\u001b[0m               mode, 'end', step, batch_logs)\n\u001b[0;32m--> 789\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[0;31m# will be handled by on_epoch_end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m       \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%cd SeniorProjectMaterial/\n",
    "EPOCHS = 1\n",
    "history = model.fit(x=dtgen.next_train_batch(),\n",
    "            epochs=EPOCHS,\n",
    "            steps_per_epoch=dtgen.steps['train'],\n",
    "            validation_data=dtgen.next_valid_batch(),\n",
    "            validation_steps=dtgen.steps['valid'],\n",
    "            callbacks=callbacks,\n",
    "            shuffle=True,\n",
    "            verbose=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: line 0: cd: SeniorProjectMaterial/: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cd SeniorProjectMaterial/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kuadmin01/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_model/Flor/iam_word_htr/assets\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save(f\"saved_model/Flor/{INPUT_SOURCE_NAME}_htr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2875768"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(f\"saved_model/Flor/{INPUT_SOURCE_NAME}_htr\")\n",
    "\n",
    "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "#                                        tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "\n",
    "converter.experimental_new_converter = True\n",
    "tflite_model = converter.convert()\n",
    "open(f\"{INPUT_SOURCE_NAME}_Flor_htr.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'SeniorProjectMaterial/'\n",
      "/home/kuadmin01/terng/SeniorProjectMaterial\n"
     ]
    }
   ],
   "source": [
    "%cd SeniorProjectMaterial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICT_IMAGE_SRC = \"hello.png\"\n",
    "tokenizer = Tokenizer(chars=CHARS, max_text_length=MAX_TEXT_LENGTH)\n",
    "img = preproc(PREDICT_IMAGE_SRC, input_size=INPUT_SHAPE)\n",
    "x_test = normalization([ img ])\n",
    "\n",
    "STEPS = 1\n",
    "\n",
    "out = model.predict(\n",
    "        x=x_test,\n",
    "        batch_size=None,\n",
    "        verbose=False,\n",
    "        steps=STEPS,\n",
    "        callbacks=None, \n",
    "        max_queue_size=10,\n",
    "        workers=1,\n",
    "        use_multiprocessing=False\n",
    "      )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0\n",
    "batch_size = int(np.ceil(len(out) / STEPS))\n",
    "input_length = len(max(out, key=len))\n",
    "predicts, probabilities = [], []\n",
    "\n",
    "while steps_done < STEPS:\n",
    "    index = steps_done * batch_size\n",
    "    until = index + batch_size\n",
    "\n",
    "    x_test = np.asarray(out[index:until])\n",
    "    x_test_len = np.asarray([input_length for _ in range(len(x_test))])\n",
    "\n",
    "    decode, log = keras.backend.ctc_decode(\n",
    "                  x_test,\n",
    "                  x_test_len,\n",
    "                  greedy=True,\n",
    "                  beam_width=10,\n",
    "                  top_paths=3\n",
    "                )\n",
    "\n",
    "    probabilities.extend([np.exp(x) for x in log])\n",
    "    decode = [[[int(p) for p in x if p != -1] for x in y] for y in decode]\n",
    "    predicts.extend(np.swapaxes(decode, 0, 1))\n",
    "    # update step\n",
    "    steps_done += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "sequence_length is not a vector [Op:CTCBeamSearchDecoder]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-70afed05622f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     decode, log = tf.nn.ctc_beam_search_decoder(\n\u001b[1;32m     15\u001b[0m                   \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                   \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/ctc_ops.py\u001b[0m in \u001b[0;36mctc_beam_search_decoder_v2\u001b[0;34m(inputs, sequence_length, beam_width, top_paths)\u001b[0m\n\u001b[1;32m    363\u001b[0m       \u001b[0mbeam_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeam_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m       \u001b[0mtop_paths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m       merge_repeated=False)\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/ctc_ops.py\u001b[0m in \u001b[0;36mctc_beam_search_decoder\u001b[0;34m(inputs, sequence_length, beam_width, top_paths, merge_repeated)\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mbeam_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeam_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m           \u001b[0mtop_paths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m           merge_repeated=merge_repeated))\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m   return ([\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_ctc_ops.py\u001b[0m in \u001b[0;36mctc_beam_search_decoder\u001b[0;34m(inputs, sequence_length, beam_width, top_paths, merge_repeated, name)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[0mbeam_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"beam_width\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: sequence_length is not a vector [Op:CTCBeamSearchDecoder]"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "steps_done = 0\n",
    "batch_size = int(np.ceil(len(out) / STEPS))\n",
    "input_length = len(max(out, key=len))\n",
    "predicts, probabilities = [], []\n",
    "\n",
    "while steps_done < STEPS:\n",
    "    index = steps_done * batch_size\n",
    "    until = index + batch_size\n",
    "\n",
    "    x_test = np.asarray(out[index:until])\n",
    "    x_test_len = np.asarray([input_length for _ in range(len(x_test))])\n",
    "\n",
    "    decode, log = tf.nn.ctc_beam_search_decoder(\n",
    "                  x_test,\n",
    "                  128\n",
    "                )\n",
    "\n",
    "    probabilities.extend([np.exp(x) for x in log])\n",
    "    decode = [[[int(p) for p in x if p != -1] for x in y] for y in decode]\n",
    "    predicts.extend(np.swapaxes(decode, 0, 1))\n",
    "    # update step\n",
    "    steps_done += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = [[tokenizer.decode(x) for x in y] for y in predicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################################\n",
      "\n",
      "####################################\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n####################################\")\n",
    "for i, (pred, prob) in enumerate(zip(predicts, probabilities)):\n",
    "  print(\"\\nProb.  - Predict\")\n",
    "  for (pd, pb) in zip(pred, prob):\n",
    "    print(f\"{pb:.4f} - {pd}\")\n",
    "print(\"\\n####################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-a1e019592675>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensorboard'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--reload_interval=300 --logdir={'log/Flor/iam_word/_epochs.log'} \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2305\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2306\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2307\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2308\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorboard/notebook.py\u001b[0m in \u001b[0;36m_start_magic\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_start_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m   \u001b[0;34m\"\"\"Implementation of the `%tensorboard` line magic.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorboard/notebook.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(args_string)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0mparsed_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshlex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m   \u001b[0mstart_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStartLaunched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorboard/manager.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(arguments, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m   \u001b[0mend_time_seconds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_time_seconds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mend_time_seconds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll_interval_seconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m     \u001b[0msubprocess_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msubprocess_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%tensorboard --reload_interval=300 --logdir={'log/Flor/iam_word/_epochs.log'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 141931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
